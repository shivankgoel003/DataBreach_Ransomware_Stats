
---
title: "TODO"
subtitle: "TODO"
author: 
  - Shivank Goel
thanks: "Code and data are available at: https://github.com/shivankgoel003/DataBreach_Ransomware_Stats"
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
header-includes:
   - \usepackage{tikz}
   - \usetikzlibrary{shapes.geometric, arrows.meta, positioning, fit, calc}
   - \usepackage{pgfplots} 
   - \usepackage{float}
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(readxl)
library(here)

breach_data <- read.csv(here("data/analysis_data/breach_data.csv"))
```


# Introduction

In today's digital world, every click, every online transaction, and every shared piece of data is a potential entry point for cyber threats. Cybercrime is not just evolving, rather it is expanding at an alarming rate, with both the frequency and severity of attacks rising every year. The purpose of these attacks is to harm companies and organizations financially, however, in some cases these attacks can have military or political purposes. “According to a report published by the Identity Theft Resource Center (ITRC), a record number of 1862 data breaches occurred in 2021 in the US. Sectors like healthcare, finance, business, and retail are the most commonly attacked, impacting millions of Americans every year” (https://www.upguard.com/blog/biggest-data-breaches-us)

Despite such severe threats and impacts of cyberattacks, still certain companies tend to oversee this concern. As per PWC 2024 Global Digital Trust Insights report, “about one-third of organisations have no risk management plan to address cloud service provider challenges. Half are ‘very satisfied’ with their technology capabilities in key cybersecurity areas. More than 30% of companies don’t consistently follow what should be standard practices of cyber defence.” (https://www.pwc.com/us/en/services/consulting/cybersecurity-risk-regulatory/library/global-digital-trust-insights.html)

Therefore, in response to such attacks, there is a need for a plan, that not just keep the intruder or hackers out but also quickly alert if an attack does happen. Our study looks at cyber resilience, which is “ the ability to anticipate, withstand, recover from, and adapt to adverse conditions, stresses, attacks, or compromises on systems that use or are enabled by cyber resources.” as defined by National Institute of Standards and Technology (https://csrc.nist.gov/glossary/term/cyber_resiliency). To thoroughly analyze our study, we break it into three major research questions :

**RQ1**: How do things like the size of the company and the type of business it does affect its ability to handle cyber attacks?

**RQ2**: Which methods or strategies used by companies work best to reduce the damage from cyber attacks?

**RQ3**: How does the business’s specific situation, like its industry or how much it relies on digital tools, change the impact of cyber attacks on it?

The estimand of our study is the measurable effect of specific characteristics of an organization including size, sector and digital intensity on their cyber resilience. As a key finding, our regression models reveal factors such as organizational size, sector, and digital intensity significantly influence an organization's cyber resilience posture.For example, larger companies often have stronger defenses against cyber attacks, and on the other hand, companies that use a lot of digital technology in their work have different levels of protection.

We aim to study and answer these questions by performing an analysis on a dataset of data breaches and ransomware attacks over 14 years from 2004, published by the University of Queensland. 

The remainder of this paper is structured as follows: @sec-data provides an overview of our methodology, including the data collection process and the analytical techniques used to explore the dataset of cyber attacks. We provide the background and overview of the study in @sec-background. @sec-model presents the regression models, discussing how we applied these models to understand the impact of various factors like organizational size, sector, and digital intensity on cyber resilience, @sec-results displays the interpretations of the model alongside other findings from analyzing the data, and @sec-discussion provides a discussion on the implications of the findings as well as the weaknesses of this paper and its next steps for further study on this subject.

# Background {#sec-background}

As discussed earlier, cyber resilience is about an organization's ability to keep its operations running smoothly in the face of cyber threats. It is not just about preventing cyber attacks, but also being prepared to deal with them effectively when they do happen. It is about recovery and adaptation, and extends beyond traditional cyber security measures. Cyber resilience surrounds various elements:

1. Governance: This is the structure and processes that define the organization's approach to cyber threats. It is about leadership, accountability, and ensuring that the policies are in place and followed as desired.An effective governance is characterized by use of well defined frameworks, and presence of dedicated cybersecurity roles.

- The use of well-defined frameworks that guide the organization's cybersecurity protocols.
- The presence of dedicated cybersecurity roles such as a Chief Information Security Officer can prevent damage to IT systems and network.


2. Prevention, Detection, and Recovery: These are the specific controls and strategies used to prevent attacks, detect them promptly, and recover from any damage caused. This approach involves:

- Setting up appropriate remote access controls to secure unauthorized access.
- Implementing proper network segmentation to control traffic flow and prevent the spread of threats within networks.
- Adding an encryption to protect confidential data.
- Utilizing detection systems to identify potential threats.
- Developing restructuring plans as part of recovery measures to restore systems after the attack.

3. Learning and Adapting: An organization needs to continuously learn from past incidents and attacks. It must adapt its strategies accordingly. This could involve updating its policies, training employees, and revising its approach to security.
 
4. External Factors: Factors like the industry the organization is in, its size, and its digital intensity (how much it relies on digital technology) can also impact its cyber resilience.

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=2.5 cm and 1.5 cm, % Distance between nodes
    mynode/.style={ % Style for the nodes
        ellipse, 
        draw, 
        align=center, 
        minimum width=3cm, 
        minimum height=1cm
    },
    myarrow/.style={ % Style for the arrows
        ->, 
        >=stealth, 
        thick,
        shorten <=2pt,
        shorten >=2pt
    },
    mydoublearrow/.style={ % Style for double-sided arrows
        <->, 
        >=stealth, 
        thick,
        shorten <=2pt,
        shorten >=2pt
    }
]

% Nodes
\node[mynode] (cyberres) {Cyber resilience};
\node[mynode, above left=of cyberres] (gov) {Governance};
\node[mynode, above right=of cyberres] (prev) {Prevention,\\ detection\\ and recovery};
\node[mynode, below=of cyberres] (response) {Organisation's\\ responses};
\node[mynode, left=of cyberres] (nature) {Nature of attack};
\node[mynode, right=of response] (outcomes) {Outcomes};
\node[mynode, below=of response] (exposure) {Exposure\\ factors};
\node[mynode, below=of outcomes] (severity) {Breach\\ severity};
\node[mynode, below=of exposure] (stakeholder) {Stakeholder\\ response};

% Arrows
\draw[myarrow] (gov) to[out=270,in=135] (cyberres);
\draw[myarrow] (prev) to[out=270,in=45] (cyberres);
\draw[myarrow] (nature) to[out=270,in=180] (cyberres);
\draw[myarrow] (cyberres) -- (response);
\draw[mydoublearrow] (cyberres) -- (outcomes);
\draw[mydoublearrow] (cyberres) -- (exposure);

% Reverse the direction of these arrows to point from 'outcomes' to its subcategories
\draw[myarrow] (outcomes) -- (severity);
\draw[myarrow] (outcomes) -- (stakeholder);

\end{tikzpicture}
\caption{Conceptual model of organizational cyber resilience}
\label{fig:cyber_res_model}
\end{figure}



# Data {#sec-data}

## Data Source and Collection: 
Our analysis is based on sampling of 514 data breaches and ransomware attacks spanning over 14 years from 2004 to 2019. The dataset was obtained from the website of University of Queensland, and was prepared and compiled by researchers Tsen, Elinor, Ko, Ryan, and Slapnicar, Sergeja https://espace.library.uq.edu.au/view/UQ:dfe5027  at the University of Queensland. The data is thorough and encompasses a wide range of cyber attack incidents. It offers insights into various aspects of these incidents, including the types of breaches, affected organizations, and the extent of impact.

The dataset represents a detailed aggregation of data breaches and ransomware attacks, and as per authors, it was originally sourced from publicly disclosed media reports. The data integrates information from multiple public databases such as Privacy Rights Clearinghouse, Information is Beautiful, the Repository of Industrial Security Incidents, and Carnegie Mellon’s list of Banking Cyber Incidents. These sources were chosen for their public accessibility and frequent citation in academic and industry literature. The approach to data collection was guided by the PRISMA methodology which ensured a systematic and thorough compilation process. 

## Data Cleaning 

We used R [@citeR] and @rohan for data cleaning and processing, utilizing packages like tidyverse [@tidy] for data manipulation and janitor [@jan] for cleaning column names. Other packages used includes `ggplot2` [@ggplot], `dplyr` [@dp], `readr` [@read], `tibble` [@tib], `janitor` [@jan],`reshape2` [@reshape], `knitr` [@knit], `ggbeeswarm` [@gg], `ggrepel` [@repel], `kableExtra`[@kable], `readxl`[@readxl], `MASS`[@mass], `rstanarm`[@rstan], `modelsummary`[@model] and `here` [@here].

The cyber breach data was preprocessed to remove inconsistencies and irrelevant information. Firstly,
variable names were simplified and standardized for consistency and ease of analysis. A key challenge  faced was the significant number of missing values in the 'number of users affected' column. This variable was central to our study as we aimed to study trends related to the scale of impact using linear regression analysis. To address this issue, a choice was made to exclude records with missing or uncertain values in this column. While this decision resulted in some data loss, it was a necessary measure to maintain the integrity and accuracy of our trend analysis. Also, in columns like 'attack_type' and 'organisation_size', missing values were replaced with "Unknown" to maintain data integrity. 

## Measurement and Exploratory Data Analysis

As part of the measurement, we converted  real-world cyber incidents into quantifiable data within our dataset. The dataset variables were defined and measured based on the nature of the cyber incidents they represent. Each entry in the dataset corresponds to a distinct cyber incident, with variables relating to the incident. Here is how we defined and measured key variables:

- **`organisation_size`**: This categorical variable categorizes the size of the affected organization into 'Small', 'Medium', 'Large', or 'Unknown', based on the number of employees or annual revenue as per commonly accepted business standards.

- **`sector`**: The sector to which the affected organization belongs is classified according to standard industry classifications. This ensures each entry aligns with the appropriate economic sector.

- **`cyber_security_role`**: This binary variable indicates the presence (`Yes`) or absence (`No`) of a dedicated cybersecurity role within the organization, at the time of the incident.

- **`number_of_users_affected`**: Represented as a numerical variable, this measures the estimated number of individuals whose data was compromised during the breach

- **`undertook_investigation`**: It captures whether an investigation was initiated following the cyber incident (1 for Yes, 0 for No).

- **`breach_severity`**: To highlight the complexity and impact of cyber incidents, we introduced a custom variable, `breach_severity`. This variable was constructed to study the nature of cyber breaches, combining several key aspects of an incident:


- **`impact_on_data`**: This reflects the nature of data compromise during the breach (categorized as 'High', 'Medium', or 'Low').

- **`subsequent_fraudulent_use_of_data`**: Considers if the breached data was later used for fraudulent activities.

The `breach_severity` variable was formulated through a custom function in our data processing script, which combined these elements to classify each incident into 'High', 'Medium', or 'Low' severity categories. This classification was based on the overall impact, the nature of data compromised, and the extent of misuse of data. This measure provides an understanding of the impact of each breach, beyond the simple binary or categorical measures commonly used. 

To achieve a clear understanding of the data, we include a variety of graphs and tables that represent the characteristics of each variable within our dataset. These visualizations illustrate the distribution and relationships among key variables, offering a broad picture of the patterns and trends among our data. @tbl-summary
shows the summary statistics for organization size and sector. For each category within these variables, we present the count and the relative frequency, expressed as a percentage of the total sample. The frequency distribution of variables such as organisation_size and sector indicates the diversity of the dataset showing various sizes of organizations and a range of sectors. Table \ref{cyber_security_stats} shows  the decripitive statistics for certain variables. 

*CS Role Yes (27.27%)*: This shows that approximately 27% of the organizations in the dataset have a designated Cyber Security (CS) role. 

*CS Role No (72.73%)*: Conversely, nearly 73% of organizations do not have a designated CS role.

*Framework Yes (36.36%)*: About 36% of the organizations adhere to a cyber security framework. Such frameworks provide structured guidelines and best practices for managing cyber security risks.

*Framework No (63.64%)*: The majority, approximately 64%, do not follow a specific cyber security framework. 

*Prevention Low (45%)*:  45% of the organizations were categorized as having Low prevention measures, indicating basic or minimal preventive security measures. 

*Prevention Medium (36.36%)*: 36.36% fell into the Medium prevention category, suggesting more substantial but not so strong security measures. 

*Prevention High (18.18%)*: Only 18.18% were classified under High prevention, reflecting strong preventive strategies against cyber threats.


```{r}
#| label: tbl-summary
#| fig-cap: Summary Statistics for Organization Size and Sector
#| echo: false
#| warning: false
#| message: false
# Load the necessary libraries
library(dplyr)
library(knitr)
library(kableExtra)

# Assuming 'organisation_size' and 'sector' are some of the variables you want summarized
# Create a function that will return the summary statistics you need
get_summary_stats <- function(data, variable_name) {
  summary_stats <- data %>%
    group_by(!!sym(variable_name)) %>%
    summarise(
      Count = n(),
      Frequency = n() / nrow(data) * 100
    ) %>%
    ungroup() %>%
    arrange(desc(Frequency))
  
  return(summary_stats)
}

# Call the function for 'organisation_size'
summary_organisation_size <- get_summary_stats(breach_data, "organisation_size")

# Call the function for 'sector'
summary_sector <- get_summary_stats(breach_data, "sector")


summary_combined <- rbind(
  data.frame(
    Variable = rep("a. Organization Size", nrow(summary_organisation_size)),
    Category = summary_organisation_size$organisation_size,
    Count = summary_organisation_size$Count,
    `Frequency (%)` = round(summary_organisation_size$Frequency, 2)
  ),
  data.frame(
    Variable = rep("b. Sector", nrow(summary_sector)),
    Category = summary_sector$sector,
    Count = summary_sector$Count,
    `Frequency (%)` = round(summary_sector$Frequency, 2)
  )
)

# Create the table using kable and add LaTeX formatting
kable(summary_combined, format = "latex", booktabs = TRUE, escape = FALSE) %>%
  kable_styling(latex_options = c("striped", "scale_down")) %>%
  add_header_above(c(" " = 1, "Summary Statistics" = 3)) %>%
  pack_rows("Organization Size", 1, nrow(summary_organisation_size), bold = TRUE) %>%
  pack_rows("Sector", nrow(summary_organisation_size) + 1, nrow(summary_combined), bold = TRUE)

```


\begin{table}[H]
\centering
\caption{Descriptive Statistics for Cyber Security Variables}
\label{cyber_security_stats} 
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Variable} & \textbf{Frequency (\%)} \\ \midrule
\multicolumn{2}{@{}l}{\textit{a. Governance (N = 514)}} \\
CS Role Yes & 27.27 \\
CS Role No & 72.73 \\ \addlinespace
\multicolumn{2}{@{}l}{\textit{b. Cyber Security Frameworks (N = 514)}} \\
Framework Yes & 36.36 \\
Framework No & 63.64 \\ \addlinespace
\multicolumn{2}{@{}l}{\textit{c. Prevention, Detection and Recovery}} \\
Prevention Low & 45.45 \\
Prevention Medium & 36.36 \\
Prevention High & 18.18 \\ \addlinespace
\end{tabular}
\end{table}

In order to observe the trend of number of cyberattacks over a span of years, from 2004 to 2019,
we plotted a line graph [@fig-attacks]. It is evident from the plot that the frequency of attacks has fluctuated over the years, with a peak in 2017. However, the decline following this peak may indicate the impact of improved cybersecurity measures, or a possible transition to different types of cyber threats not captured in this dataset. This visualization provides an overview of the nature of cyber threats and the ongoing battle between cybersecurity efforts and threat actors.


```{r}
#| label: fig-attacks
#| fig-cap: Cyberattacks Over Time
#| echo: false
#| warning: false

breach_data %>%
  count(year) %>%
  ggplot(aes(x = as.factor(year), y = n)) +  # Convert year to factor to treat it as discrete
  geom_line(group=1) +  # Ensure geom_line treats the data as connected points
  scale_x_discrete(breaks = levels(as.factor(breach_data$year))) +  # Specify breaks at every level of the factor
  labs(x = "Year", y = "Number of Attacks") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))  # Rotate x labels to fit them all

``` 
We also plotted a bar graph @fig-sector to count the number of incidents across various sectors. The bar chart clearly indicates that the 'Human Health Activities' sector has the highest count of incidents, standing out significantly from the other sectors. This might suggest that health sector is a more frequent target for cyber incidents or probably it is more diligent in reporting such events. The other sectors show a range of incident counts, with most appearing to have far fewer incidents in comparison. This could point to different levels of risk exposure, varying security measures, or reporting practices across these sectors. 

```{r}
#| label: fig-sector
#| fig-cap: Bar Plot of Sector
#| echo: false
#| warning: false

ggplot(breach_data, aes(x = sector)) +
  geom_bar(fill = "coral", color = "black") +
  labs(x = "Sector", y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = rel(0.8)),
        plot.margin = unit(c(1,1,1,4), "lines")) 


```

[@fig-overviewofattack] is a creative visualization that effectively depicts the distribution and comparison of cyber attacks across various countries, with a specific emphasis on the United States. It combines a stacked bar chart for multiple countries and a line plot for the USA allowing for a dual-axis comparison due to the disproportionate number of attacks in the USA compared to other countries.

The bar segments represent the frequency of attacks in countries such as Australia, Canada, Japan, the UK, and others, with each color corresponding to a different country. The stacked nature of the bars shows how the total number of attacks is divided among these countries within each year.

The line plot, on the other hand, tracks the frequency of cyber attacks in the USA across the same timeframe, adjusted by a scale factor for direct comparison on a secondary y-axis. This representation highlights the stark contrast in the volume of attacks between the USA and other countries while providing a clear year-by-year trend analysis.

The choice to categorize all countries with fewer attacks under a consolidated "Other" category is a practical approach to maintain clarity in the visualization, avoiding overcrowding the chart with too many individual country representations.


```{r}
#| label: fig-overviewofattack
#| fig-cap: Overview of Cyber Attacks by Year and Country
#| echo: false
#| warning: false

breach_data$year <- as.numeric(as.character(breach_data$year))

# Now proceed with your data manipulation
breach_data_summary <- breach_data %>%
  mutate(country = fct_collapse(country,
                                "Other" = setdiff(unique(country), 
                                                   c("USA", "Australia", "Canada", "Global", "Japan", "UK")))) %>%
  group_by(year, country) %>%
  summarize(frequency = n(), .groups = 'drop')

# Separating the data by country for ease of plotting
country_data <- breach_data_summary %>%
  filter(country != "USA")

usa_data <- breach_data_summary %>%
  filter(country == "USA") %>%
  arrange(year)

# Ensure year is numeric for the line plot
breach_data_summary$year <- as.numeric(as.character(breach_data_summary$year))

# Recalculate max frequencies if necessary
max_usa_freq <- max(usa_data$frequency, na.rm = TRUE)
max_other_freq <- max(country_data$frequency, na.rm = TRUE)

# Determine scale factor for secondary axis
scale_factor <- max_other_freq / max_usa_freq
breach_data_summary$year <- as.numeric(as.character(breach_data_summary$year))
breach_data_summary <- breach_data_summary %>% filter(!is.na(year))

# Plot
# Define a color palette
formal_palette <- c("Australia" = "#4878D0", "Canada" = "#6ACC65", "Global" = "#D65F5F", 
                    "Japan" = "#B47CC7", "UK" = "#C4AD66", "Other" = "#77BEDB")

# Plot
gg <- ggplot() +
  # Add bars for all countries except USA
  geom_bar(data = country_data, aes(x = year, y = frequency, fill = country), stat = "identity", position = position_stack()) +
  # Add line for USA
  geom_line(data = usa_data, aes(x = year, y = frequency * scale_factor, group = 1), color = "#4D4D4D", size = 1) +
  # Define the primary y-axis with the secondary axis for the USA
  scale_y_continuous(
    name = "Frequency of Cyber Attacks (Other Countries except USA)", 
    limits = c(0, max_other_freq * 1.1),  # Set limits for better control, slightly above max to ensure space for the line
    sec.axis = sec_axis(~ . / scale_factor, name = "Frequency of USA Cyber Attacks", labels = scales::comma)
  ) +
  # Set breaks for the x-axis to unique years
  scale_x_continuous(breaks = sort(unique(breach_data_summary$year))) +
  # Apply the formal color palette
  scale_fill_manual(values = formal_palette) +
  labs(subtitle = "Bar plots for Other countries; line plot for USA") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1), # Rotate x-axis labels
        legend.position = "bottom", # Adjust the position of the legend
        plot.title = element_text(hjust = 0.5), # Center the plot title
        plot.subtitle = element_text(hjust = 0.5)) # Center the plot subtitle


# Print the plot
print(gg)

```
[@fig-attacktype] represents a stacked area chart, with each colored layer representing a different type of attack, allowing for an easy comparison of their occurrences over time. It is clear that some attack types, like installed malware, show peaks and troughs, possibly depicting the nature of cyber threats and security measures. These trends can be helpful for understanding the changing landscape of cyber risks and preparing for future security strategies.

```{r}
#| label: fig-attacktype
#| fig-cap: Attack Types Over Years
#| echo: false
#| warning: false

attack_type_palette <- c(
  "Installed malware" = "#4878D0", 
  "Misuse of resources" = "#6ACC65", 
  "Physical Theft" = "#D65F5F", 
  "Unknown" = "#B47CC7", 
  "Web compromise" = "#C4AD66"
)

breach_data %>%
  count(year, attack_type) %>%
  ggplot(aes(x = year, y = n, fill = attack_type)) +
  geom_area(position = 'stack') +
  labs(x = "Year", 
       y = "Count", 
       fill = "Attack Type") +
  scale_fill_manual(values = attack_type_palette)
```
# Model {#sec-model}

## Model Set-up

After performing exploratory data analysis, we got a broad overview of the general trend between different variables of our dataset. To strengthen answers to our research question claims made earlier, we implement  regression models and take a close look at what makes an organization good at dealing with cyber threats. We use these models to understand how certain factors, like the size of a company or the industry, affect its ability to handle a cyberattack.

**Simple Models for Numbers (Linear Regression):**

We were interested in knowing how often cyberattacks happen and how bad they are based on the company's size or the kind of work it does. We use linear regression for this. 
The basic form of a linear regression equation is 

$Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_n X_n + \varepsilon$

Where:
- $Y$ is the outcome we're interested in.

- $\beta_0$ is the intercept, the starting point of our equation when all our predictors (Xs) are zero.

- $\beta_1, \beta_2, ..., \beta_n$ are the coefficients. These tell us how much change we expect in $Y$ for a one-unit change in each predictor $X$, assuming all other predictors are held constant.

- $X_1, X_2, ..., X_n$ are the predictor variables. 

- $\varepsilon$ represents the error term. It accounts for the difference between our predicted value of $Y$ and its actual value.

We expected to study if bigger companies, for example, have more cyberattacks or not. In form of equation we can represent it as follows:

$\text{Impact} = (\text{Base Impact}) + (\text{Effect of Company Size}) + (\text{Effect of Industry}) + \dots$


**Complex Models for Yes/No Outcomes (Bayesian Logistic Regression)**:

Now, what if we want to know if a company will take action after an attack, like starting an investigation? This is a yes/no type of question. We use a different method called logistic regression, which is good for when the outcome is not a number but a choice between two things.

## Specific models for Research Question 

**RQ1: Organizational attributes and cyberattack handling**

To address the first research question about how an organization's size and business type affect its ability to handle cyber attacks, we developed a specific linear regression model. This model examines the relationships between various organizational attributes and the handling of cyberattacks. It predicts the severity of cyber breaches based on:

1. Organizational Size (Medium, Small, Unknown)
2. Digital Intensity (Low, Low-Medium, Medium-High)
3. Sector (e.g., Public Administration and Defence, Education, Health)
4. Country

- Dependent Variable: Severity of cyber breaches.

- Independent Variables: Organizational size, sector, digital intensity, and geographical location.

[@tbl-modelbreachseverity] summarises the results from model.

1. Organisation Size: The coefficients for different organization sizes (Medium, Small, Unknown) indicate how the severity of breaches changes with these categories compared to the baseline category. Medium (0.015) and Small (0.103) have positive coefficients, which suggests potentially higher severity compared to the baseline. Unknown (-0.072) indicates a lower severity than the baseline, which might reflect missing data issues or other factors.

2. Level of Digital Intensity & Sector: These coefficients show how levels of digital intensity and different sectors affect breach severity. Negative coefficients, like for the public administration and defence sector (-0.581), suggest a lower severity compared to the baseline sector.

3. Country: Similar to sectors, the coefficients for different countries compared to the baseline indicate variations in breach severity across geographical locations.

R-squared (0.137): Indicates the proportion of variance in the dependent variable that's predictable from the independent variables. A value of 0.137 suggests the model explains about 13.7% of the variability in breach severity.

Adjusted R-squared (0.099): It adjusts the R-squared for the number of predictors in the model. It is lower than the R-squared, which is common in models with many predictors.

AIC (665.5) and BIC (746.7): These are measures for model comparison.


**RQ2: Effectiveness of cybersecurity methods**

**RQ3: Impact of specific business situations**

```{r}
#| echo: false
#| eval: true
#| warning: false
#| label: tbl-modelbreachseverity
#| tbl-cap: "Linear Regression Model Summary for RQ1"
#| message: false
#| 
library(modelsummary)

breach_severity_model <- readRDS(file = here::here("models/breach_severity_model.rds"))

modelsummary(list("Linear Regression" = breach_severity_model))

```



```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| 
library(modelsummary)

logistic_model <- readRDS(file = here::here("models/restructuring_model.rds"))

modelsummary(list("Logistic Regression" = logistic_model))

```



```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

breach_data %>%
  group_by(year) %>%
  summarize(total_users_affected = sum(number_of_users_affected, na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = total_users_affected)) +
  geom_line() +
  labs(title = "Number of Users Affected Over Years",
       x = "Year",
       y = "Total Number of Users Affected") +
  theme_minimal()

```




```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
# Summary statistics for numerical variables
summary(breach_data$number_of_users_affected)
summary(breach_data$year)

# Frequency tables for categorical variables
table(breach_data$sector)
table(breach_data$organisation_size)
table(breach_data$critical_industry)
table(breach_data$level_of_digital_intensity)
table(breach_data$country)
table(breach_data$cyber_security_role)
table(breach_data$cyber_security_frameworks)
table(breach_data$education_and_awareness_policy)
table(breach_data$policy)
table(breach_data$prevention_detection_and_recovery)
table(breach_data$detector)
table(breach_data$restructuring_after_attack)
table(breach_data$bribe_ransom_paid)
table(breach_data$free_identity_or_credit_theft_monitoring)
table(breach_data$additional_disclosure_of_information)
table(breach_data$overall_nature_of_attack)
table(breach_data$attack_type)
table(breach_data$attacker)
table(breach_data$attack_vector)
table(breach_data$impact_on_data)
# ... continue for other categorical variables as needed

# Histogram for a continuous variable (e.g., number_of_users_affected)
ggplot(breach_data, aes(x = number_of_users_affected)) +
  geom_histogram(binwidth = 1000, fill = "blue", color = "black") +
  labs(title = "Histogram of Number of Users Affected", x = "Number of Users Affected", y = "Frequency")

```

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

linear_model_RQ2 <- readRDS(file = here::here("models/linear_model_RQ2.rds"))
# Plotting diagnostics for the linear regression model (Example: linear_model_RQ2)
ggplot(breach_data, aes(x = year, y = number_of_users_affected)) +
  geom_point() +
  geom_smooth(method = "lm", color = "blue") +
  labs(title = "Linear Regression of Number of Users Affected Over Years", 
       x = "Year", 
       y = "Number of Users Affected")

# Assuming breach_data is your dataset and you have already created models named linear_model_severity and linear_model_investigations

# Partial regression plot for breach severity with a specific predictor (e.g., 'organisation_size')
# install.packages("car") # Uncomment if the car package is not installed

```



```{r regression-table, results='asis', echo=FALSE}

library(broom)
library(stargazer)
model_investigation <- readRDS(file = here::here("models/model_investigation.rds"))

model_investigation_frame <- augment(model_investigation)


ggplot(model_investigation_frame, aes(x = organisation_size, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dotted", color = "grey") +
  theme_classic() +
  labs(y = "Residuals", x = "Organisation Size")

ggplot(model_investigation_frame, aes(x = .resid)) +
  geom_histogram(binwidth = 1) +
  theme_classic() +
  labs(y = "Number of occurrences", x = "Residuals")

```
$\begin{table}[!htbp] \centering 
  \caption{Linear regression analysis with dependent variable} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{1}{c}{\textit{Dependent variable:}} \\ 
\cline{2-2} 
\\[-1.8ex] & undertook\_investigation \\ 
\hline \\[-1.8ex] 
 critical\_industry & $-$0.03 (0.12) \\ 
  organisation\_sizeMedium & $-$0.04 (0.06) \\ 
  organisation\_sizeSmall & 0.07 (0.08) \\ 
  organisation\_sizeUnknown & $-$0.03 (0.06) \\ 
  level\_of\_digital\_intensityLow & $-$0.03 (0.62) \\ 
  level\_of\_digital\_intensityLow-Medium & $-$0.29 (0.67) \\ 
  level\_of\_digital\_intensityMedium-High & $-$0.31 (0.66) \\ 
  sectorAdministrative and support service & $-$0.62 (0.72) \\ 
  sectorAdvertising and other business services & $-$0.48 (0.66) \\ 
  sectorArts, entertainment and recreation & $-$0.14 (0.12) \\ 
  sectorChemicals and chemical products & 0.20 (0.37) \\ 
  sectorComputer, electronic and optical products & 0.19 (0.23) \\ 
  sectorConstruction & $-$0.61 (0.45) \\ 
  sectorEducation & $-$0.11 (0.18) \\ 
  sectorElectrical equipment & $-$0.23 (0.51) \\ 
  sectorElectricity, gas, steam and air conditioning & $-$0.56 (0.34) \\ 
  sectorFinance and insurance & $-$0.09 (0.63) \\ 
  sectorFood products, beverages and tobacco & $-$0.06 (0.26) \\ 
  sectorHuman health activities & $-$0.14 (0.22) \\ 
  sectorIT and other information services & $-$0.29 (0.63) \\ 
  sectorLegal and accounting activities & $-$0.63 (0.69) \\ 
  sectorMachine equipment & $-$0.08 (0.24) \\ 
  sectorPharmaceutical products & $-$0.27 (0.38) \\ 
  sectorPublishing, audiovisual and broadcasting & $-$0.12 (0.22) \\ 
  sectorResidential care and social work activities & $-$0.18 (0.24) \\ 
  sectorScientific research and development & $-$0.37 (0.68) \\ 
  sectorTelecommunications & $-$0.40 (0.65) \\ 
  sectorTextiles, wearing apparel and leather &  \\ 
  sectorTransportation storage & 0.06 (0.31) \\ 
  sectorWholesale, retail trade and repair &  \\ 
  countryChina & 0.88 (0.51) \\ 
  countryFrance & $-$0.17 (0.51) \\ 
  countryGermany & $-$0.01 (0.40) \\ 
  countryGlobal & 0.28 (0.29) \\ 
  countryHong Kong & 0.56 (0.57) \\ 
  countryIndia & $-$0.33 (0.51) \\ 
  countryJapan & 0.13 (0.35) \\ 
  countryNorway & 0.04 (0.50) \\ 
  countryPhilippines & $-$0.15 (0.51) \\ 
  countryQatar & $-$0.33 (0.51) \\ 
  countryRussia & $-$0.12 (0.41) \\ 
  countrySingapore & 0.83$^{*}$ (0.36) \\ 
  countrySouth Africa & 0.85 (0.51) \\ 
  countrySouth Korea & 0.53 (0.36) \\ 
  countryTurkey & 0.85 (0.51) \\ 
  countryUAE & 0.60 (0.57) \\ 
  countryUK & 0.35 (0.31) \\ 
  countryUSA & 0.19 (0.26) \\ 
  Constant & 0.45 (0.70) \\ 
 \hline \\[-1.8ex] 
Observations & 513 \\ 
R$^{2}$ & 0.15 \\ 
Adjusted R$^{2}$ & 0.07 \\ 
Residual Std. Error & 0.43 (df = 465) \\ 
F Statistic & 1.80$^{**}$ (df = 47; 465) \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{1}{r}{$^{*}$p$<$0.05; $^{**}$p$<$0.01; $^{***}$p$<$0.001} \\ 
\end{tabular} 
\end{table} $





\newpage


# References
